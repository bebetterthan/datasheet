# Security Dataset Scraper Configuration
# =======================================

# General Settings
general:
  output_dir: "data"
  log_level: "INFO"
  max_workers: 5
  cache_enabled: true
  cache_dir: ".cache"

# GitHub API Settings (for OWASP, PayloadsAllTheThings, etc.)
# Without token: 60 requests/hour
# With token: 5000 requests/hour
github:
  token: "" # Set via GITHUB_TOKEN env var or here
  api_base: "https://api.github.com"
  raw_base: "https://raw.githubusercontent.com"

# Scraping Settings
scraping:
  timeout: 30
  max_retries: 3
  retry_delay: 1.0
  concurrent_requests: 10
  respect_robots_txt: true
  user_agent: "SecurityDatasetScraper/1.0 (+https://github.com/security-dataset-scraper)"

# Rate Limiting
rate_limiting:
  enabled: true
  requests_per_second: 2.0
  burst_size: 5
  adaptive: true
  min_delay: 0.5
  max_delay: 10.0

# Proxy Configuration
proxy:
  enabled: false
  rotation_strategy: "round_robin" # round_robin, random, weighted_random
  proxies: []
  # Example:
  # - url: "http://proxy1.example.com:8080"
  #   username: ""
  #   password: ""
  # - url: "socks5://proxy2.example.com:1080"

# Processing Settings
processing:
  min_content_length: 100
  max_content_length: 50000
  min_quality_score: 0.5
  deduplicate: true
  similarity_threshold: 0.85

# Output Settings
output:
  format: "alpaca" # alpaca, sharegpt, openai, jsonl
  split_dataset: true
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  include_metadata: true

# LLM Settings (for augmentation)
llm:
  enabled: false
  provider: "openai"
  model: "gpt-3.5-turbo"
  api_key: "" # Or use OPENAI_API_KEY env var
  max_tokens: 1000
  temperature: 0.7

# Source-specific Settings
sources:
  hacktricks:
    enabled: true
    priority: 1
    max_pages: 1000
    categories:
      - "generic-methodologies-and-resources"
      - "linux-hardening"
      - "windows-hardening"
      - "pentesting-web"
      - "network-services-pentesting"

  ctf_writeups:
    enabled: true
    priority: 2
    max_pages: 500
    platforms:
      - "ctftime"
      - "0xdf"

  exploit_db:
    enabled: true
    priority: 3
    max_pages: 1000
    types:
      - "webapps"
      - "remote"
      - "local"
    # Use GitLab mirror instead of main site (avoids Cloudflare)
    use_gitlab_mirror: true
    # Or use offline database
    use_offline_db: false
    offline_db_path: "data/exploitdb"

  cve:
    enabled: true
    priority: 4
    max_pages: 500
    min_cvss: 7.0
    days_back: 365

  nuclei_templates:
    enabled: true
    priority: 5
    max_pages: 1000
    categories:
      - "cves"
      - "vulnerabilities"
      - "exposures"
      - "misconfiguration"

  payloads:
    enabled: true
    priority: 6
    max_pages: 500

  owasp:
    enabled: true
    priority: 7
    max_pages: 500
    resources:
      - "cheatsheets"
      - "wstg"
      - "top10"

# Category Weights (for balancing dataset)
category_weights:
  web_security: 1.5
  exploitation: 1.3
  privilege_escalation: 1.2
  credential_access: 1.1
  recon: 1.0
  lateral_movement: 1.0
  defense_evasion: 1.0
  persistence: 0.9
  cryptography: 0.8
